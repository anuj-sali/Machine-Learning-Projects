{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INTERNSHIP:**GRADUATE ROTATIONAL INTERNSHIP PROGRAM( GRIP) ORGANIZED BY THE SPARK FOUNDATION\n",
    "\n",
    "**INTERN:** ANUJ SALI\n",
    "\n",
    "**FUNCTION:** DATA SCIENCE & BUSINESS ANALYTICS\n",
    "\n",
    "**TASK 1:** SUPERVISED MACHINE LEARNING PROBLEM\n",
    "\n",
    "**PROBLEM STATEMENT:** FIND SCORE FOR HOURS=9.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING NECCESSARY PYTHON LIBRARIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET THE DATA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('task1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.2</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.5</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.3</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.7</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.7</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.9</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.5</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.3</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.9</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.1</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.4</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.7</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.8</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.8</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.9</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7.8</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hours  Scores\n",
       "0     2.5      21\n",
       "1     5.1      47\n",
       "2     3.2      27\n",
       "3     8.5      75\n",
       "4     3.5      30\n",
       "5     1.5      20\n",
       "6     9.2      88\n",
       "7     5.5      60\n",
       "8     8.3      81\n",
       "9     2.7      25\n",
       "10    7.7      85\n",
       "11    5.9      62\n",
       "12    4.5      41\n",
       "13    3.3      42\n",
       "14    1.1      17\n",
       "15    8.9      95\n",
       "16    2.5      30\n",
       "17    1.9      24\n",
       "18    6.1      67\n",
       "19    7.4      69\n",
       "20    2.7      30\n",
       "21    4.8      54\n",
       "22    3.8      35\n",
       "23    6.9      76\n",
       "24    7.8      86"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hours  Scores\n",
       "0    2.5      21\n",
       "1    5.1      47\n",
       "2    3.2      27\n",
       "3    8.5      75\n",
       "4    3.5      30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25 entries, 0 to 24\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Hours   25 non-null     float64\n",
      " 1   Scores  25 non-null     int64  \n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 528.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.012000</td>\n",
       "      <td>51.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.525094</td>\n",
       "      <td>25.286887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.100000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.700000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.800000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.400000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Hours     Scores\n",
       "count  25.000000  25.000000\n",
       "mean    5.012000  51.480000\n",
       "std     2.525094  25.286887\n",
       "min     1.100000  17.000000\n",
       "25%     2.700000  30.000000\n",
       "50%     4.800000  47.000000\n",
       "75%     7.400000  75.000000\n",
       "max     9.200000  95.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNOW THE INITIAL DATA INSIGHTS: PLOTTING A HISTOGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'Hours'}>,\n",
       "        <AxesSubplot:title={'center':'Scores'}>]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABrUAAANeCAYAAAC8jYU2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABEU0lEQVR4nO3df7Std10f+PenSVgNP5TWwBGTQHDMWJEI4m3AwdGTWm1g0LRdtk0mhcZVmqUDrXZia+ofOHVWV+202OqApHc0g65BsmwFzUgUWNZTUBc2QANJCNQ0xuYaBgQ0cIGKl37mj7Ojh5Nz7tlnn+fs/T33vF5rnXX3fp5nP8/n+7nPfs793vfZz6nuDgAAAAAAAIzsT626AAAAAAAAANiLUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAvgmKqqB6vqL25bdkNV/dqqagIAAICdVNU3VNVvVNUjVfWJqvr1qvrzq64LgOU6f9UFAHBuq6rzu/vMqusAAADgaKqqL0ryi0m+O8nPJnlckv8xyR9OeIzzuvvzU+0PgMPhk1oA7KiqvqqqNqrqD6rq3qr69i3rNqrq5Vuef8EnvKqqq+oVVfVbSX6rNv3Lqvro7Kfq3l9Vz17ykAAAADia/vsk6e43dvfnu/uz3f227n5/klTV36mq+6rqU1X1gap63mz52ea1r6+q11XVHVX16SRXVdWXVdXPVdXvVdVvV9Xf27L9lVX17qr6ZFV9pKp+ZMk9ACBCLQB2UFUXJPl/k7wtyVOT/N0kb6iqr9zHbv5ykucneVaSb03yjdmciDw5yd9I8vHpKgYAAOAc9p+SfL6qfqqqXlRVf+bRFVX115L8b0leluSLknx7ko/POa/9n5P8kyRPSvIbs+3fl+TiJN+c5Hur6i/Ntv3RJD/a3V+U5L/L5ifGAFgyoRbA8fbzs59Y+4Oq+oMkPz5b/oIkT0zyw939ue7+d9m81cN1+9j3P+3uT3T3Z5P8UTYnCX8uSXX3fd394emGAQAAwLmquz+Z5BuSdJL/K8nvVdXtVbWW5OVJ/o/uvrM33d/dv5P55rW/0N2/3t3/LckVSZ7S3T802/6B2bGunW37R0m+oqou6u7T3f2uZYwdgC8k1AI43v5ydz/50a8k/8ts+ZcleWj2D/tH/U42f1ptXg89+mA2eXhNktcm+UhVnZzdEx0AAAD2NPvhyBu6+5Ikz87mvPVfJbk0yX/e4SXzzGsf2vL4GUm+bNsPfv5AkrXZ+r+dzbuPfLCq7qyql0wwLAD2SagFwE4eTnJpVW39PvH0JL87e/zpJI/fsu5Ld9hHf8GT7h/r7q9L8tXZnAj8g+nKBQAA4Ljo7g8meX02w62Hsnk7wO32mtcmXzhvfSjJb2/9wc/uflJ3v3h2zN/q7uuyeSvDf5bk31bVEyYbFABzEWoBsJPfzGZw9Q+r6oKqWk/ybUlum62/K8lfrarHV9VXZPMn1nZVVX++qp4/u6f5p5P81ySfP6TaAQAAOIdU1Z+rqpuq6pLZ80uzeRvBdyX5iSTfV1VfV5u+oqqekb3ntdv9hySfrKrvr6oLq+q8qnp2Vf352TH/ZlU9ZfbJrz+Yvca8FmDJhFoAPEZ3fy6bv1z3RUk+ls3ftfWy2U/DJcm/TPK5JB9J8lNJ3rDHLr8om/ci//1s3u7h40n+xfSVAwAAcA76VJLnJ/nNqvp0NsOse5Lc1N3/Jsk/SfIzs+1+PsmfnWNe+wW6+/PZDL2em+S3Z6/5iSRfPNvk6iT3VtXpJD+a5Nru/q+TjxSAs6ru3nsrAAAAAAAAWCGf1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhnf+qgvYyUUXXdSXXXbZoe3/05/+dJ7whCcc2v6PC32chj5OQx8PTg+noY/T0MeD08NpnAt9fM973vOx7n7KquuAc91hz2NHcS5cF0ejp9PT0+np6fT0dFr6OT09nZ6e7s9uc9khQ63LLrss7373uw9t/xsbG1lfXz+0/R8X+jgNfZyGPh6cHk5DH6ehjwenh9M4F/pYVb+z6hrgODjseewozoXr4mj0dHp6Oj09nZ6eTks/p6en09PT/dltLuv2gwAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8PYMtarq0qr61aq6r6rurarv2WGbqqofq6r7q+r9VfW8LeuurqoPzdbdPPUAAAAAYB5V9aer6j9U1ftm89t/vMM2u85vAQCA1Zrnk1pnktzU3V+V5AVJXlFVz9q2zYuSXD77ujHJ65Kkqs5L8trZ+mcluW6H1wIAAMAy/GGSv9Ddz0ny3CRXV9ULtm2z4/wWAABYvT1Dre7+cHe/d/b4U0nuS3Lxts2uSfLTveldSZ5cVU9LcmWS+7v7ge7+XJLbZtsCAADAUs3mrKdnTy+YffW2zXab3wIAACtW3dv//X6WjasuS/KOJM/u7k9uWf6LSX64u39t9vxXknx/ksuSXN3dL58tf2mS53f3K3fY943Z/Cm4rK2tfd1tt9224JD2dvr06TzxiU88tP0fFyP08e7ffWQpx7ni4i8+tH2P0MdzgT4enB5OQx+noY8Hp4fTOBf6eNVVV72nu0+sug4YxeyOIu9J8hVJXtvd379t/Y7z2+5+9w77Wto8dhTnwnVx1bbPY9cuTD7y2bO/5jDnpOci5+n09HR6ejot/Zyenk5PT/dnt7ns+fPuoKqemOTnknzv1kDr0dU7vKTPsvyxC7tPJjmZJCdOnOj19fV5S9u3jY2NHOb+j4sR+njDzW9ZynEevH790PY9Qh/PBfp4cHo4DX2chj4enB5OQx/h3NPdn0/y3Kp6cpI3V9Wzu/ueLZsMOY8dheviwW2fx950xZm8+u6z//fMYc5Jz0XO0+np6fT0dFr6OT09nZ6eTmOe36mVqrogm4HWG7r7TTtscirJpVueX5Lk4bMsBwAAgJXp7j9IspHk6m2rzGMBAGBQe4ZaVVVJfjLJfd39I7tsdnuSl9WmFyR5pLs/nOTOJJdX1TOr6nFJrp1tCwAAAEtVVU+ZfUIrVXVhkr+Y5IPbNtttfgsAAKzYPLcffGGSlya5u6rumi37gSRPT5LuviXJHUlenOT+JJ9J8p2zdWeq6pVJ3prkvCS3dve9Uw4AAAAA5vS0JD81+71afyrJz3b3L1bVdyVnn98CAACrt2eoNfvluDvdU3zrNp3kFbusuyObkwIAAABYme5+f5Kv3WH5LVse7zq/BQAAVmuu36kFAAAAAAAAqyTUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB45++1QVXdmuQlST7a3c/eYf0/SHL9lv19VZKndPcnqurBJJ9K8vkkZ7r7xFSFAwAAAAAAcHzM80mt1ye5ereV3f3Pu/u53f3cJP8oyb/v7k9s2eSq2XqBFgAAAAAAAAvZM9Tq7nck+cRe281cl+SNB6oIAAAAAAAAttnz9oPzqqrHZ/MTXa/csriTvK2qOsm/7u6TZ3n9jUluTJK1tbVsbGxMVdpjnD59+lD3f1yM0MebrjizlOM4H8enjwenh9PQx2no48Hp4TT0EQAAAMYxWaiV5NuS/Pq2Ww++sLsfrqqnJnl7VX1w9smvx5gFXieT5MSJE72+vj5haV9oY2Mjh7n/42KEPt5w81uWcpwHr18/tH2P0MdzgT4enB5OQx+noY8Hp4fT0EcAAAAYxzy/U2te12bbrQe7++HZnx9N8uYkV054PAAAAAAAAI6JSUKtqvriJN+U5Be2LHtCVT3p0cdJvjXJPVMcDwAAAAAAgONlz9sPVtUbk6wnuaiqTiX5wSQXJEl33zLb7K8keVt3f3rLS9eSvLmqHj3Oz3T3L09XOgAAAAAAAMfFnqFWd183xzavT/L6bcseSPKcRQsDAAAAAACAR035O7UAAAAAAADgUAi1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAA4Fqrq0qr61aq6r6rurarv2WGb9ap6pKrumn29ahW1AgAAj3X+qgsAAACAJTmT5Kbufm9VPSnJe6rq7d39gW3bvbO7X7KC+gAAgLPwSS0AAACOhe7+cHe/d/b4U0nuS3LxaqsCAADmJdQCAADg2Kmqy5J8bZLf3GH111fV+6rql6rqq5dbGQAAsBu3HwQAAOBYqaonJvm5JN/b3Z/ctvq9SZ7R3aer6sVJfj7J5bvs58YkNybJ2tpaNjY2Dq3mUZw+ffpYjPMw3XTFmS94vnbhY5dtp+f74zydnp5OT0+npZ/T09Pp6ek0hFoAAAAcG1V1QTYDrTd095u2r98acnX3HVX141V1UXd/bIdtTyY5mSQnTpzo9fX1wyt8EBsbGzkO4zxMN9z8li94ftMVZ/Lqu8/+3zMPXr9+iBWde5yn09PT6enptPRzeno6PT2dhtsPAgAAcCxUVSX5yST3dfeP7LLNl862S1Vdmc1588eXVyUAALAbn9QCAADguHhhkpcmubuq7pot+4EkT0+S7r4lyXck+e6qOpPks0mu7e5eQa0AAMA2Qi0AAACOhe7+tSS1xzavSfKa5VQEAADsh9sPAgAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMPbM9Sqqlur6qNVdc8u69er6pGqumv29aot666uqg9V1f1VdfOUhQMAAAAAAHB8zPNJrdcnuXqPbd7Z3c+dff1QklTVeUlem+RFSZ6V5LqqetZBigUAAAAAAOB42jPU6u53JPnEAvu+Msn93f1Ad38uyW1JrllgPwAAAAAAABxz50+0n6+vqvcleTjJ93X3vUkuTvLQlm1OJXn+bjuoqhuT3Jgka2tr2djYmKi0xzp9+vSh7v+4GKGPN11xZinHcT6OTx8PTg+noY/T0MeD08Np6CMAAACMY4pQ671JntHdp6vqxUl+PsnlSWqHbXu3nXT3ySQnk+TEiRO9vr4+QWk729jYyGHu/7gYoY833PyWpRznwevXD23fI/TxXKCPB6eH09DHaejjwenhNPQRAAAAxjHP79Q6q+7+ZHefnj2+I8kFVXVRNj+ZdemWTS/J5ie5AAAAAAAAYF8OHGpV1ZdWVc0eXznb58eT3Jnk8qp6ZlU9Lsm1SW4/6PEAAAAAAAA4fva8/WBVvTHJepKLqupUkh9MckGSdPctSb4jyXdX1Zkkn01ybXd3kjNV9cokb01yXpJbZ79rCwAAAAAAAPZlz1Cru6/bY/1rkrxml3V3JLljsdIAAAAAAABg04FvPwgAAAAAAACHTagFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAHAtVdWlV/WpV3VdV91bV9+ywTVXVj1XV/VX1/qp63ipqBQAAHuv8VRcAAAAAS3ImyU3d/d6qelKS91TV27v7A1u2eVGSy2dfz0/yutmfAADAivmkFgAAAMdCd3+4u987e/ypJPcluXjbZtck+ene9K4kT66qpy25VAAAYAc+qQUAAMCxU1WXJfnaJL+5bdXFSR7a8vzUbNmHd9jHjUluTJK1tbVsbGwcRqlDOX369LEY52G66YozX/B87cLHLttOz/fHeTo9PZ2enk5r9H7e/buPLPS6Ky7+4okrmd/oPT2K9HQaQi0AAACOlap6YpKfS/K93f3J7at3eEnvtJ/uPpnkZJKcOHGi19fXpyxzSBsbGzkO4zxMN9z8li94ftMVZ/Lqu8/+3zMPXr9+iBWde5yn09PT6enptEbv5/Zr/7xWef0fvadHkZ5Ow+0HAQAAODaq6oJsBlpv6O437bDJqSSXbnl+SZKHl1EbAABwdkItAAAAjoWqqiQ/meS+7v6RXTa7PcnLatMLkjzS3Y+59SAAALB8bj8IAADAcfHCJC9NcndV3TVb9gNJnp4k3X1LkjuSvDjJ/Uk+k+Q7l18mAACwE6EWAAAAx0J3/1p2/p1ZW7fpJK9YTkUAAMB+uP0gAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADD2zPUqqpbq+qjVXXPLuuvr6r3z75+o6qes2Xdg1V1d1XdVVXvnrJwAAAAAAAAjo95Pqn1+iRXn2X9byf5pu7+miT/e5KT29Zf1d3P7e4Ti5UIAAAAAADAcXf+Xht09zuq6rKzrP+NLU/fleSSCeoCAAAAAACAP7ZnqLVPfzvJL2153kneVlWd5F939/ZPcf2xqroxyY1Jsra2lo2NjYlL+xOnT58+1P0fFyP08aYrzizlOM7H8enjwenhNPRxGvp4cHo4DX0EAACAcUwWalXVVdkMtb5hy+IXdvfDVfXUJG+vqg929zt2ev0s8DqZJCdOnOj19fWpSnuMjY2NHOb+j4sR+njDzW9ZynEevH790PY9Qh/PBfp4cHo4DX2chj4enB5OQx8BAABgHPP8Tq09VdXXJPmJJNd098cfXd7dD8/+/GiSNye5corjAQAAAAAAcLwcONSqqqcneVOSl3b3f9qy/AlV9aRHHyf51iT3HPR4AAAAAAAAHD973n6wqt6YZD3JRVV1KskPJrkgSbr7liSvSvIlSX68qpLkTHefSLKW5M2zZecn+Znu/uVDGAMAAAAAAADnuD1Dre6+bo/1L0/y8h2WP5DkOYuXBgAAAAAAAJsm+Z1aAAAAAAAAcJiEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMb89Qq6puraqPVtU9u6yvqvqxqrq/qt5fVc/bsu7qqvrQbN3NUxYOAAAA+zXHHHe9qh6pqrtmX69ado0AAMDO5vmk1uuTXH2W9S9Kcvns68Ykr0uSqjovyWtn65+V5LqqetZBigUAAIADen3OPsdNknd293NnXz+0hJoAAIA57Blqdfc7knziLJtck+Sne9O7kjy5qp6W5Mok93f3A939uSS3zbYFAACAlZhjjgsAAAxqit+pdXGSh7Y8PzVbtttyAAAAGNnXV9X7quqXquqrV10MAACwqbp7742qLkvyi9397B3WvSXJP+3uX5s9/5Uk/zDJlyf5S9398tnylya5srv/7i7HuDGbty/M2tra1912220LDWgep0+fzhOf+MSzbnP37z6y7/1ecfEX7/s1yzrOYRxrnj4etkXGtIhFez6PrX1c1ngWtaxzfJFjLfN8XNaYFj3WosdZuzD5yGcP9ziLGvmavN28fVxm/5Zlyr+nw3hPH6XzaB571TZlD0cZ05TmHdN+r43bjfBev+qqq97T3SdWXQeMZI857hcl+W/dfbqqXpzkR7v78l32s7R57ChGmAceddu/B83zvWaE7ydHifN0eno6PT2d1uj9XOb/JU1l9J4eRXq6P7vNZc+fYN+nkly65fklSR5O8rhdlu+ou08mOZkkJ06c6PX19QlK29nGxkb22v8NN79l3/t98Pqz73OVxzmMY83Tx8O2yJgWsWjP57G1j8saz6KWdY4vcqxlno/LGtOix1r0ODddcSavvnv+bwuH+b7YbuRr8nbz9nGZ/VuWKf+eDuM9fZTOo3nsVduUPRxlTFOad0z7vTZudy6+1+Fc192f3PL4jqr68aq6qLs/tsO2S5vHjmKEeeBRt/170Dzfa3w/2R/n6fT0dHp6Oq3R+7nM/0uayug9PYr0dBpT3H7w9iQvq00vSPJId384yZ1JLq+qZ1bV45JcO9sWAAAAhlRVX1pVNXt8ZTbnzR9fbVUAAEAyxye1quqNSdaTXFRVp5L8YJILkqS7b0lyR5IXJ7k/yWeSfOds3ZmqemWStyY5L8mt3X3vIYwBAAAA5jLHHPc7knx3VZ1J8tkk1/Y89+0HAAAO3Z6hVndft8f6TvKKXdbdkc3QCwAAAFZujjnua5K8ZknlAAAA+zDF7QcBAAAAAADgUAm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABjeXKFWVV1dVR+qqvur6uYd1v+Dqrpr9nVPVX2+qv7sbN2DVXX3bN27px4AAAAAAAAA577z99qgqs5L8tok35LkVJI7q+r27v7Ao9t09z9P8s9n239bkr/f3Z/Yspuruvtjk1YOAAAAAADAsTHPJ7WuTHJ/dz/Q3Z9LcluSa86y/XVJ3jhFcQAAAAAAAJDMF2pdnOShLc9PzZY9RlU9PsnVSX5uy+JO8raqek9V3bhooQAAAAAAABxfe95+MEntsKx32fbbkvz6tlsPvrC7H66qpyZ5e1V9sLvf8ZiDbAZeNybJ2tpaNjY25ihtMadPn95z/zddcWbf+12k5mUd5zCONU8fD9siY1rEss7HZY1nUcs6xxc51jLPx2WNadFjLXqctQv3d7xlvv9HviZvN28fV339PAxT/j0dxnv6KJ1H89irtil7OMqYpjTvmPZ7bdzuXHyvAwAAwKrME2qdSnLplueXJHl4l22vzbZbD3b3w7M/P1pVb87m7QwfE2p198kkJ5PkxIkTvb6+Pkdpi9nY2Mhe+7/h5rfse78PXn/2fa7yOIdxrHn6eNgWGdMiFu35PLb2cVnjWdSyzvFFjrXM83FZY1r0WIse56YrzuTVd8/zbWHx4yxq5GvydvP2cZn9W5Yp/54O4z19lM6jeexV25Q9HGVMU5p3TPu9Nm53Lr7XAQAAYFXmuf3gnUkur6pnVtXjshlc3b59o6r64iTflOQXtix7QlU96dHHSb41yT1TFA4AAAAAAMDxseePnXb3map6ZZK3Jjkvya3dfW9Vfdds/S2zTf9Kkrd196e3vHwtyZur6tFj/Ux3//KUAwAAAAAAAODcN9e9VLr7jiR3bFt2y7bnr0/y+m3LHkjynANVCAAAAAAAwLE3z+0HAQAAAAAAYKWEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAAAAAwPCEWgAAAAAAAAxPqAUAAAAAAMDwhFoAAAAAAAAMT6gFAAAAAADA8IRaAAAAAAAADE+oBQAAwLFRVbdW1Uer6p5d1ldV/VhV3V9V76+q5y27RgAAYGdCLQAAAI6T1ye5+izrX5Tk8tnXjUlet4SaAACAOQi1AAAAODa6+x1JPnGWTa5J8tO96V1JnlxVT1tOdQAAwNmcv+oCAAAAYCAXJ3loy/NTs2Uf3r5hVd2YzU9zZW1tLRsbG8uob1d3/+4jh36MtQuT//MNv7DQa6+4+Iv3/ZpljGlRi4wnSW664swXPF+78LHLtlvWubVovxftxWE5ffr0H/dsmefQsvqwyJgOWtvWnh6GVYzpsO01poNcT7cbuRfLeg+uXbi8a+Ui9rrO72aVY9rrfb/M7xkj/3sgmX9Mh30t3cm5eH0VagEAAMCfqB2W9U4bdvfJJCeT5MSJE72+vn6IZe3thpvfcujHuOmKM3n13Yv9V8KD16/v+zXLGNOiFhlP8tgxzdPTRY+1X4v2e1n1zWtjYyOPvh+XeQ6N/Pd00Nq29vQwrGJMh22vMR3kerrdyL1Y1nvwpivO5K+v+Pvw2RzF6+te7/tljmnkfw8k84/psK+lOzkXr69uPwgAAAB/4lSSS7c8vyTJwyuqBQAA2EKoBQAAAH/i9iQvq00vSPJIdz/m1oMAAMDyuf0gAAAAx0ZVvTHJepKLqupUkh9MckGSdPctSe5I8uIk9yf5TJLvXE2lAADAdkItAAAAjo3uvm6P9Z3kFUsqBwAA2Ae3HwQAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4c4VaVXV1VX2oqu6vqpt3WL9eVY9U1V2zr1fN+1oAAAAAAADYy/l7bVBV5yV5bZJvSXIqyZ1VdXt3f2Dbpu/s7pcs+FoAAAAAAADY1Tyf1Loyyf3d/UB3fy7JbUmumXP/B3ktAAAAAAAAJJkv1Lo4yUNbnp+aLdvu66vqfVX1S1X11ft8LQAAAAAAAOxqz9sPJqkdlvW25+9N8ozuPl1VL07y80kun/O1mwepujHJjUmytraWjY2NOUpbzOnTp/fc/01XnNn3fhepeVnHOYxjzdPHw7bImBaxrPNxWeNZ1LLO8UWOtczzcVljWvRYix5n7cL9HW+Z7/+Rr8nbzdvHVV8/D8OUf0+H8Z4+SufRPPaqbcoejjKmKc07pv1eG7c7F9/rAAAAsCrzhFqnkly65fklSR7eukF3f3LL4zuq6ser6qJ5XrvldSeTnEySEydO9Pr6+jz1L2RjYyN77f+Gm9+y7/0+eP3Z97nK4xzGsebp42FbZEyLWLTn89jax2WNZ1HLOscXOdYyz8dljWnRYy16nJuuOJNX3z3Pt4XFj7Ooka/J283bx2X2b1mm/Hs6jPf0UTqP5rFXbVP2cJQxTWneMe332rjdufheBwAAgFWZ5/aDdya5vKqeWVWPS3Jtktu3blBVX1pVNXt85Wy/H5/ntQAAAAAAALCXPX/stLvPVNUrk7w1yXlJbu3ue6vqu2brb0nyHUm+u6rOJPlskmu7u5Ps+NpDGgsAAAAAAADnqLnupdLddyS5Y9uyW7Y8fk2S18z7WgAAAAAAANiPeW4/CAAAAAAAACsl1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAACOjaq6uqo+VFX3V9XNO6xfr6pHququ2derVlEnAADwWOevugAAAABYhqo6L8lrk3xLklNJ7qyq27v7A9s2fWd3v2TpBQIAAGflk1oAAAAcF1cmub+7H+juzyW5Lck1K64JAACYk09qAQAAcFxcnOShLc9PJXn+Dtt9fVW9L8nDSb6vu+/daWdVdWOSG5NkbW0tGxsb01a7TzddcebQj7F24eLHWaQ/yxjTohb9+94+pnl6uqxza5l/t4fp9OnTf1zTMs+hkf+eDlrb1p4ehlWM6bDtNaaDXE+3G7kXy3oPrl14bvZhlWPa633v3wN/Yt4xHfa1dCfn4vVVqAUAAMBxUTss623P35vkGd19uqpenOTnk1y+0866+2SSk0ly4sSJXl9fn67SBdxw81sO/Rg3XXEmr757sf9KePD69X2/ZhljWtQi40keO6Z5errosfZr0X4vq755bWxs5NH34zLPoZH/ng5a29aeHoZVjOmw7TWmg1xPtxu5F8t6D950xZn89RV/Hz6bo3h93et9v8wxjfzvgWT+MR32tXQn5+L11e0HAQAAOC5OJbl0y/NLsvlprD/W3Z/s7tOzx3ckuaCqLlpeiQAAwG6EWgAAABwXdya5vKqeWVWPS3Jtktu3blBVX1pVNXt8ZTbnzR9feqUAAMBjuP0gAAAAx0J3n6mqVyZ5a5Lzktza3fdW1XfN1t+S5DuSfHdVnUny2STXdvf2WxQCAAArINQCAADg2JjdUvCObctu2fL4NUles+y6AACAvbn9IAAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMDyhFgAAAAAAAMMTagEAAAAAADA8oRYAAAAAAADDE2oBAAAAAAAwPKEWAAAAAAAAwxNqAQAAAAAAMLy5Qq2qurqqPlRV91fVzTusv76q3j/7+o2qes6WdQ9W1d1VdVdVvXvK4gEAAAAAADgezt9rg6o6L8lrk3xLklNJ7qyq27v7A1s2++0k39Tdv19VL0pyMsnzt6y/qrs/NmHdAAAAAAAAHCPzfFLryiT3d/cD3f25JLcluWbrBt39G939+7On70pyybRlAgAAAAAAcJzt+UmtJBcneWjL81P5wk9hbfe3k/zSlued5G1V1Un+dXef3OlFVXVjkhuTZG1tLRsbG3OUtpjTp0/vuf+brjiz7/0uUvOyjnMYx5qnj4dtkTEtYlnn47LGs6hlneOLHGuZ5+OyxrTosRY9ztqF+zveMt//I1+Tt5u3j6u+fh6GKf+eDuM9fZTOo3nsVduUPRxlTFOad0z7vTZudy6+1wEAAGBV5gm1aodlveOGVVdlM9T6hi2LX9jdD1fVU5O8vao+2N3veMwON8Ouk0ly4sSJXl9fn6O0xWxsbGSv/d9w81v2vd8Hrz/7Pld5nMM41jx9PGyLjGkRi/Z8Hlv7uKzxLGpZ5/gix1rm+bisMS16rEWPc9MVZ/Lqu+f5trD4cRY18jV5u3n7uMz+LcuUf0+H8Z4+SufRPPaqbcoejjKmKc07pv1eG7c7F9/rAAAAsCrz3H7wVJJLtzy/JMnD2zeqqq9J8hNJrunujz+6vLsfnv350SRvzubtDAEAAAAAAGBu84Radya5vKqeWVWPS3Jtktu3blBVT0/ypiQv7e7/tGX5E6rqSY8+TvKtSe6ZqngAAAAAAACOhz3vpdLdZ6rqlUnemuS8JLd2971V9V2z9bckeVWSL0ny41WVJGe6+0SStSRvni07P8nPdPcvH8pIAAAAAAAAOGfN9QsCuvuOJHdsW3bLlscvT/LyHV73QJLnHLBGAAAAAAAAjrl5bj8IAAAAAAAAKyXUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4Qi0AAAAAAACGJ9QCAAAAAABgeEItAAAAAAAAhifUAgAAAAAAYHhCLQAAAAAAAIYn1AIAAAAAAGB4c4VaVXV1VX2oqu6vqpt3WF9V9WOz9e+vqufN+1oAAABYloPMbwEAgNXaM9SqqvOSvDbJi5I8K8l1VfWsbZu9KMnls68bk7xuH68FAACAQ3eQ+S0AALB683xS68ok93f3A939uSS3Jblm2zbXJPnp3vSuJE+uqqfN+VoAAABYhoPMbwEAgBWr7j77BlXfkeTq7n757PlLkzy/u1+5ZZtfTPLD3f1rs+e/kuT7k1y212u37OPGbP4UXJJ8ZZIPHWxoZ3VRko8d4v6PC32chj5OQx8PTg+noY/T0MeD08NpnAt9fEZ3P2XVRcAIDjK/7e5377C/Zc5jR3EuXBdHo6fT09Pp6en09HRa+jk9PZ2enu7PjnPZ8+d4Ye2wbHsStts287x2c2H3ySQn56jnwKrq3d19YhnHOpfp4zT0cRr6eHB6OA19nIY+HpweTkMf4ZxzkPntYxcucR47CtfF6enp9PR0eno6PT2dln5OT0+np6fTmCfUOpXk0i3PL0ny8JzbPG6O1wIAAMAyHGR+CwAArNg8v1PrziSXV9Uzq+pxSa5Ncvu2bW5P8rLa9IIkj3T3h+d8LQAAACzDQea3AADAiu35Sa3uPlNVr0zy1iTnJbm1u++tqu+arb8lyR1JXpzk/iSfSfKdZ3vtoYxkf47V7SEOkT5OQx+noY8Hp4fT0Mdp6OPB6eE09BHOIQeZ3/LHXBenp6fT09Pp6en09HRa+jk9PZ2enk6gune8NTgAAAAAAAAMY57bDwIAAAAAAMBKCbUAAAAAAAAY3rEKtarq1qr6aFXds+pajrKqurSqfrWq7quqe6vqe1Zd01FTVX+6qv5DVb1v1sN/vOqajrKqOq+q/mNV/eKqazmqqurBqrq7qu6qqnevup6jqKqeXFX/tqo+OLs+fv2qazpqquorZ+fgo1+frKrvXXVdR1FV/f3Z95d7quqNVfWnV13TUVNV3zPr373OQ+C42m3uV1V/tqreXlW/Nfvzz6y61qNgt3mgfh7c9jmhnh7MTvNDPT2YneaLerq43eaOerq4neaQ+nkwO80p9XQaxyrUSvL6JFevuohzwJkkN3X3VyV5QZJXVNWzVlzTUfOHSf5Cdz8nyXOTXF1VL1htSUfa9yS5b9VFnAOu6u7ndveJVRdyRP1okl/u7j+X5DlxTu5bd39odg4+N8nXJflMkjevtqqjp6ouTvL3kpzo7mcnOS/Jtaut6mipqmcn+TtJrszm+/klVXX5aqsCWInd5n43J/mV7r48ya/MnrO33eaB+nlw2+eEenpw2+eHenowO80X9XRBZ5k76ukCzjKH1M8FnWVOqacTOFahVne/I8knVl3HUdfdH+7u984efyqb34gvXm1VR0tvOj17esHsq1dY0pFVVZck+Z+S/MSqa+H4qqovSvKNSX4ySbr7c939Byst6uj75iT/ubt/Z9WFHFHnJ7mwqs5P8vgkD6+4nqPmq5K8q7s/091nkvz7JH9lxTUBLN1Z5n7XJPmp2WY/leQvr6TAI+Ys80D9PIBd5oR6Oj09XdBZ5ot6Oo2tc0c9XdxOc0j9XNxuc0o9ncCxCrWYXlVdluRrk/zmiks5cma3R7gryUeTvL279XAx/yrJP0zy31Zcx1HXSd5WVe+pqhtXXcwR9OVJfi/J/z277clPVNUTVl3UEXdtkjeuuoijqLt/N8m/SPJfknw4ySPd/bbVVnXk3JPkG6vqS6rq8UlenOTSFdcEsFLb5n5r3f3hZDP4SvLUFZZ2pOwyD9TPg/lXeeycUE8PZqf5oZ4ubrf5op5OY+vcUU8XcJY5pH4ubrc5pZ5OQKjFwqrqiUl+Lsn3dvcnV13PUdPdn599TPqSJFfOPpbKPlTVS5J8tLvfs+pazgEv7O7nJXlRNm8r842rLuiIOT/J85K8rru/Nsmn4yPkC6uqxyX59iT/ZtW1HEWze3Jfk+SZSb4syROq6m+utqqjpbvvS/LPkrw9yS8neV82b8EFcCyZ+03HPHBa5oSHxvxwWuaLh8TccRrmkNMzpzxcQi0WUlUXZHNS84buftOq6znKZh8534jf97aIFyb59qp6MMltSf5CVf0/qy3paOruh2d/fjSb96G+crUVHTmnkpza8onLf5vNSQuLeVGS93b3R1ZdyBH1F5P8dnf/Xnf/UZI3JfkfVlzTkdPdP9ndz+vub8zm7at/a9U1AazCLnO/j1TV02brn5bNTx2xD9vmgfq5uN3mhHp6ALvMD/V0cbvNF/X04LbPHfV0MbvNIfXzAHaZU+rpBIRa7FtVVTbvA3xfd//Iqus5iqrqKVX15NnjC7P5zeODKy3qCOruf9Tdl3T3Zdn8uPm/624/SbJPVfWEqnrSo4+TfGs2PybNnLr7/0vyUFV95WzRNyf5wApLOuqui1sPHsR/SfKCqnr87Hv2N+cLf3E6c6iqp87+fHqSvxrnJHAMnWXud3uSvzV7/LeS/MKyazuKzjIP1M8FnWVOqKcLOsv8UE8XdJb5op4e3Pa5o54uZrc5pH4ewC5zSj2dQHX3qmtYmqp6Y5L1JBcl+UiSH+zun1xpUUdQVX1DkncmuTt/cs/qH+juO1ZX1dFSVV+TzV8GeF42w+Wf7e4fWm1VR1tVrSf5vu5+yYpLOXKq6suz+dN3yeZtEX6mu//JCks6kqrqudn85dSPS/JAku/s7t9faVFH0Oxe0w8l+fLufmTV9RxVVfWPk/yNbN7e4D8meXl3/+FqqzpaquqdSb4kyR8l+V+7+1dWXBLA0u0298vm79X62SRPz+Z/hP217v7ESoo8QnabB1bVl0Q/D2zrnFBPF7fb/FBPD2an+WJm14Ho6UJ2mjs6Txe30xwyyROjnwvbaU7pHJ3GsQq1AAAAAAAAOJrcfhAAAAAAAIDhCbUAAAAAAAAYnlALAAAAAACA4Qm1AAAAAAAAGJ5QCwAAAAAAgOEJtQAAAAAAABieUAsAAAAAAIDh/f+mB1GBLYXEcQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 2160x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(bins=50,figsize=(30,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights: Corresponding to a specific score(for ex. 30),there exists multiple hours(for ex. 2.5,2.7 and 3.5)\n",
    "Looking at x axis: hours range from 1.1 to 9.2\n",
    "whereas scores range from 17 to 95\n",
    "Lets scale the data so as to minimize the error due to this significant range difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIVISION OF DATA SET INTO TRAIN AND TEST SET:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "    Hours  Scores\n",
      "22    3.8      35\n",
      "17    1.9      24\n",
      "24    7.8      86\n",
      "23    6.9      76\n",
      "14    1.1      17\n",
      "1     5.1      47\n",
      "10    7.7      85\n",
      "13    3.3      42\n",
      "8     8.3      81\n",
      "6     9.2      88\n",
      "18    6.1      67\n",
      "4     3.5      30\n",
      "9     2.7      25\n",
      "7     5.5      60\n",
      "20    2.7      30\n",
      "3     8.5      75\n",
      "0     2.5      21\n",
      "21    4.8      54\n",
      "15    8.9      95\n",
      "12    4.5      41\n",
      "         Test Set:\n",
      "    Hours  Scores\n",
      "5     1.5      20\n",
      "2     3.2      27\n",
      "19    7.4      69\n",
      "16    2.5      30\n",
      "11    5.9      62\n"
     ]
    }
   ],
   "source": [
    "train_set,test_set=train_test_split(df,test_size=0.2,random_state=0)\n",
    "print('''Train Set:\\n{}\n",
    "         Test Set:\\n{}'''.format(train_set,test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Exploratory Data Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x155055a3988>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, a aproximate linear relationship is present between no. of hours and scores which is logically correct :)\n",
    "We can also see one major insight that Linear Regression model *might* work good on this specific data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION FOR TRAINING OF ML MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=df1[['Hours']],df1[['Scores']]               #DOUBLE BRACKETS INDICATE 2D ARRAY WHICH SKLEARN MODEL TAKES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler       #We have already talked about it. We need to scale hours\n",
    "scaler=StandardScaler()                                #to reduce error, so as to improve accuracy.\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECTING & TRAINING OUR ML MODEL:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since already mentioned, lets first try to fit linear regression on our training set:\n",
    "Lets import mean_absolute_error,mean_squared_error to calculate Root Mean Square:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[86.25874013]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_hour=X_train.iloc[[-5]]\n",
    "some_score=y_train.iloc[[-5]]\n",
    "some_hour_scaled=scaler.transform(some_hour)\n",
    "lin_reg.predict(some_hour_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scores\n",
       "3      75"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can clearly see our model is UNDERFITTING the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lin_reg.predict((X_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\t:5.18660170918037\n",
      "RMSE:\t 5.5586133502263415\n"
     ]
    }
   ],
   "source": [
    "print('''MAE:\\t:{}\\nRMSE:\\t {}'''.format(mean_absolute_error(y_train,y_pred),np.sqrt(mean_squared_error(y_train,y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets go a step further and train our linear regression model using CROSS VALIDATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t[5.80272632 6.61255747 5.71501951 6.83521614 5.82350259]\n",
      "Mean:\t:6.157804405423847\n",
      "Standard Deviation:\t0.4689527931487401\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores_lin=cross_val_score(lin_reg,X_train_scaled,y_train,cv=5,scoring='neg_mean_squared_error')\n",
    "lin_rmse=np.sqrt(-scores_lin)\n",
    "print('''RMSE:\\t{}\\nMean:\\t:{}\\nStandard Deviation:\\t{}'''.format(lin_rmse,lin_rmse.mean(),lin_rmse.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets select a more powerful model: DecisionTreeRegressor:\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg=DecisionTreeRegressor()\n",
    "tree_reg.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tree=tree_reg.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\t:0.25\n",
      "RMSE:\t 0.7905694150420949\n"
     ]
    }
   ],
   "source": [
    "print('''MAE:\\t:{}\\nRMSE:\\t {}'''.format(mean_absolute_error(y_train,y_pred_tree),np.sqrt(mean_squared_error(y_train,y_pred_tree))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See RMSE has gone too low. This is a case of OVERFITTING the training data.\n",
    "Decision trees work by fitting multi order polynomial model on data, this is a common in Decision Tree Regressor. :)\n",
    "Lets cross validate this model to get better results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t[5.38516481 7.79422863 8.336666   8.6890736  6.63795902]\n",
      "Mean:\t:7.36861841272565\n",
      "Standard Deviation:\t1.2107694609794777\n"
     ]
    }
   ],
   "source": [
    "scores_tree=cross_val_score(tree_reg,X_train_scaled,y_train,cv=5,scoring='neg_mean_squared_error')\n",
    "tree_rmse=np.sqrt(-scores_tree)\n",
    "print('''RMSE:\\t{}\\nMean:\\t:{}\\nStandard Deviation:\\t{}'''.format(tree_rmse,tree_rmse.mean(),tree_rmse.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See its performing worse than Cross-validated Linear Regression model.\n",
    "Lets import my favourite model : RandomForestRegressor!\n",
    "RandomForestRegressor works on the concept that it train many decision trees on various subsets of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg=RandomForestRegressor(random_state=0)            #This is important since we want reproducible output and random_state\n",
    "rf_reg.fit(X_train_scaled,y_train)                                                        #is by default false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\t:2.157791666666667\n",
      "RMSE:\t 2.4136173937911347\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf=rf_reg.predict(X_train_scaled)\n",
    "print('''MAE:\\t:{}\\nRMSE:\\t {}'''.format(mean_absolute_error(y_train,y_pred_rf),np.sqrt(mean_squared_error(y_train,y_pred_rf))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t[3.23362456 7.57193972 5.44946559 6.24767557 6.91568428]\n",
      "Mean:\t:5.883677943012677\n",
      "Standard Deviation:\t1.5006053784373181\n"
     ]
    }
   ],
   "source": [
    "#This is lesser than that of both linear regressor and decision tree regressor\n",
    "#Lets cross_validate it:\n",
    "scores_rf=cross_val_score(rf_reg,X_train_scaled,y_train,cv=5,scoring='neg_mean_squared_error')\n",
    "rf_rmse=np.sqrt(-scores_rf)\n",
    "print('''RMSE:\\t{}\\nMean:\\t:{}\\nStandard Deviation:\\t{}'''.format(rf_rmse,rf_rmse.mean(),rf_rmse.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks better than cross-validated decision tree model(mean:7.37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINE TUNING OUR BEST MODEL:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final step in making more best model more perfect is HYPERPARAMETER TUNING:\n",
    "Hyperparameters are the performance parameters of the model. So, optimizing the hyperparameters is to optimize the performance\n",
    "improving accuracy and getting low generalization error when unseen data is shown to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import RandomizedSearchCV to see which are optimized hyperparamters\n",
    "And then choosing 'em in GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(random_state=0),\n",
       "                   param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000015508B1AA88>},\n",
       "                   random_state=0, return_train_score=True,\n",
       "                   scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "from scipy.stats import randint            #for generating random numbers between low and high\n",
    "param_distributribs={'n_estimators' : randint(low=1,high=500)}\n",
    "random=RandomizedSearchCV(rf_reg,param_distributions=param_distributribs,n_iter=10,cv=5,scoring='neg_mean_squared_error',random_state=0,return_train_score=True)\n",
    "random.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res=pd.DataFrame(random.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.161305</td>\n",
       "      <td>0.016825</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>173</td>\n",
       "      <td>{'n_estimators': 173}</td>\n",
       "      <td>-9.044266</td>\n",
       "      <td>-56.227312</td>\n",
       "      <td>-28.251462</td>\n",
       "      <td>-44.230955</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.608611</td>\n",
       "      <td>16.419372</td>\n",
       "      <td>7</td>\n",
       "      <td>-8.695094</td>\n",
       "      <td>-5.319815</td>\n",
       "      <td>-9.897626</td>\n",
       "      <td>-5.706401</td>\n",
       "      <td>-6.386198</td>\n",
       "      <td>-7.201027</td>\n",
       "      <td>1.785536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055400</td>\n",
       "      <td>0.008928</td>\n",
       "      <td>0.008799</td>\n",
       "      <td>0.006285</td>\n",
       "      <td>48</td>\n",
       "      <td>{'n_estimators': 48}</td>\n",
       "      <td>-10.446308</td>\n",
       "      <td>-57.166697</td>\n",
       "      <td>-28.655518</td>\n",
       "      <td>-40.285807</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.218882</td>\n",
       "      <td>15.786217</td>\n",
       "      <td>3</td>\n",
       "      <td>-10.107229</td>\n",
       "      <td>-5.711869</td>\n",
       "      <td>-10.765850</td>\n",
       "      <td>-6.649821</td>\n",
       "      <td>-6.850799</td>\n",
       "      <td>-8.017114</td>\n",
       "      <td>2.023268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.091031</td>\n",
       "      <td>0.008952</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>0.005140</td>\n",
       "      <td>118</td>\n",
       "      <td>{'n_estimators': 118}</td>\n",
       "      <td>-10.157462</td>\n",
       "      <td>-56.371000</td>\n",
       "      <td>-28.569649</td>\n",
       "      <td>-39.851031</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.318208</td>\n",
       "      <td>15.909737</td>\n",
       "      <td>4</td>\n",
       "      <td>-9.363348</td>\n",
       "      <td>-5.413532</td>\n",
       "      <td>-10.031900</td>\n",
       "      <td>-5.634848</td>\n",
       "      <td>-6.482076</td>\n",
       "      <td>-7.385141</td>\n",
       "      <td>1.933128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166458</td>\n",
       "      <td>0.016964</td>\n",
       "      <td>0.011641</td>\n",
       "      <td>0.006102</td>\n",
       "      <td>193</td>\n",
       "      <td>{'n_estimators': 193}</td>\n",
       "      <td>-9.597490</td>\n",
       "      <td>-56.112944</td>\n",
       "      <td>-28.706028</td>\n",
       "      <td>-43.731442</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.319328</td>\n",
       "      <td>15.934705</td>\n",
       "      <td>5</td>\n",
       "      <td>-8.680691</td>\n",
       "      <td>-5.375692</td>\n",
       "      <td>-9.814168</td>\n",
       "      <td>-5.663256</td>\n",
       "      <td>-6.477463</td>\n",
       "      <td>-7.202254</td>\n",
       "      <td>1.745740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.296797</td>\n",
       "      <td>0.024310</td>\n",
       "      <td>0.014860</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>324</td>\n",
       "      <td>{'n_estimators': 324}</td>\n",
       "      <td>-10.288264</td>\n",
       "      <td>-55.908381</td>\n",
       "      <td>-27.269700</td>\n",
       "      <td>-43.206683</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.480204</td>\n",
       "      <td>15.994201</td>\n",
       "      <td>6</td>\n",
       "      <td>-8.425419</td>\n",
       "      <td>-4.765895</td>\n",
       "      <td>-9.733499</td>\n",
       "      <td>-5.525123</td>\n",
       "      <td>-6.454190</td>\n",
       "      <td>-6.980825</td>\n",
       "      <td>1.842085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.212243</td>\n",
       "      <td>0.016194</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>252</td>\n",
       "      <td>{'n_estimators': 252}</td>\n",
       "      <td>-10.472472</td>\n",
       "      <td>-56.669001</td>\n",
       "      <td>-27.778414</td>\n",
       "      <td>-43.395896</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.848177</td>\n",
       "      <td>16.100104</td>\n",
       "      <td>9</td>\n",
       "      <td>-8.511471</td>\n",
       "      <td>-4.986956</td>\n",
       "      <td>-9.716744</td>\n",
       "      <td>-5.630361</td>\n",
       "      <td>-6.349219</td>\n",
       "      <td>-7.038950</td>\n",
       "      <td>1.789381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.164707</td>\n",
       "      <td>0.019650</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.006238</td>\n",
       "      <td>196</td>\n",
       "      <td>{'n_estimators': 196}</td>\n",
       "      <td>-9.235622</td>\n",
       "      <td>-55.793869</td>\n",
       "      <td>-28.116788</td>\n",
       "      <td>-43.816405</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.104335</td>\n",
       "      <td>16.052753</td>\n",
       "      <td>2</td>\n",
       "      <td>-8.765619</td>\n",
       "      <td>-5.357176</td>\n",
       "      <td>-9.875131</td>\n",
       "      <td>-5.712885</td>\n",
       "      <td>-6.518956</td>\n",
       "      <td>-7.245953</td>\n",
       "      <td>1.770213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.374593</td>\n",
       "      <td>0.034903</td>\n",
       "      <td>0.020641</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>360</td>\n",
       "      <td>{'n_estimators': 360}</td>\n",
       "      <td>-10.287719</td>\n",
       "      <td>-56.394565</td>\n",
       "      <td>-27.290578</td>\n",
       "      <td>-43.511997</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.665389</td>\n",
       "      <td>16.149283</td>\n",
       "      <td>8</td>\n",
       "      <td>-8.347305</td>\n",
       "      <td>-4.722161</td>\n",
       "      <td>-9.649546</td>\n",
       "      <td>-5.570879</td>\n",
       "      <td>-6.457735</td>\n",
       "      <td>-6.949525</td>\n",
       "      <td>1.808180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.009471</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>-7.672500</td>\n",
       "      <td>-69.037500</td>\n",
       "      <td>-32.917500</td>\n",
       "      <td>-53.975000</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.166281</td>\n",
       "      <td>20.931414</td>\n",
       "      <td>10</td>\n",
       "      <td>-12.336875</td>\n",
       "      <td>-6.867500</td>\n",
       "      <td>-13.046250</td>\n",
       "      <td>-8.230000</td>\n",
       "      <td>-6.297578</td>\n",
       "      <td>-9.355641</td>\n",
       "      <td>2.804212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.187843</td>\n",
       "      <td>0.029373</td>\n",
       "      <td>0.011778</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>212</td>\n",
       "      <td>{'n_estimators': 212}</td>\n",
       "      <td>-9.005418</td>\n",
       "      <td>-55.428319</td>\n",
       "      <td>-27.156442</td>\n",
       "      <td>-43.219395</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.890311</td>\n",
       "      <td>16.193325</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.015387</td>\n",
       "      <td>-5.465542</td>\n",
       "      <td>-10.148432</td>\n",
       "      <td>-5.836459</td>\n",
       "      <td>-6.683170</td>\n",
       "      <td>-7.429798</td>\n",
       "      <td>1.836276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.161305      0.016825         0.009945        0.003638   \n",
       "1       0.055400      0.008928         0.008799        0.006285   \n",
       "2       0.091031      0.008952         0.007864        0.005140   \n",
       "3       0.166458      0.016964         0.011641        0.006102   \n",
       "4       0.296797      0.024310         0.014860        0.000704   \n",
       "5       0.212243      0.016194         0.012566        0.001743   \n",
       "6       0.164707      0.019650         0.008986        0.006238   \n",
       "7       0.374593      0.034903         0.020641        0.003393   \n",
       "8       0.009471      0.000400         0.001803        0.000404   \n",
       "9       0.187843      0.029373         0.011778        0.001981   \n",
       "\n",
       "  param_n_estimators                 params  split0_test_score  \\\n",
       "0                173  {'n_estimators': 173}          -9.044266   \n",
       "1                 48   {'n_estimators': 48}         -10.446308   \n",
       "2                118  {'n_estimators': 118}         -10.157462   \n",
       "3                193  {'n_estimators': 193}          -9.597490   \n",
       "4                324  {'n_estimators': 324}         -10.288264   \n",
       "5                252  {'n_estimators': 252}         -10.472472   \n",
       "6                196  {'n_estimators': 196}          -9.235622   \n",
       "7                360  {'n_estimators': 360}         -10.287719   \n",
       "8                 10   {'n_estimators': 10}          -7.672500   \n",
       "9                212  {'n_estimators': 212}          -9.005418   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  ...  \\\n",
       "0         -56.227312         -28.251462         -44.230955  ...   \n",
       "1         -57.166697         -28.655518         -40.285807  ...   \n",
       "2         -56.371000         -28.569649         -39.851031  ...   \n",
       "3         -56.112944         -28.706028         -43.731442  ...   \n",
       "4         -55.908381         -27.269700         -43.206683  ...   \n",
       "5         -56.669001         -27.778414         -43.395896  ...   \n",
       "6         -55.793869         -28.116788         -43.816405  ...   \n",
       "7         -56.394565         -27.290578         -43.511997  ...   \n",
       "8         -69.037500         -32.917500         -53.975000  ...   \n",
       "9         -55.428319         -27.156442         -43.219395  ...   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0       -36.608611       16.419372                7           -8.695094   \n",
       "1       -36.218882       15.786217                3          -10.107229   \n",
       "2       -36.318208       15.909737                4           -9.363348   \n",
       "3       -36.319328       15.934705                5           -8.680691   \n",
       "4       -36.480204       15.994201                6           -8.425419   \n",
       "5       -36.848177       16.100104                9           -8.511471   \n",
       "6       -36.104335       16.052753                2           -8.765619   \n",
       "7       -36.665389       16.149283                8           -8.347305   \n",
       "8       -39.166281       20.931414               10          -12.336875   \n",
       "9       -35.890311       16.193325                1           -9.015387   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0           -5.319815           -9.897626           -5.706401   \n",
       "1           -5.711869          -10.765850           -6.649821   \n",
       "2           -5.413532          -10.031900           -5.634848   \n",
       "3           -5.375692           -9.814168           -5.663256   \n",
       "4           -4.765895           -9.733499           -5.525123   \n",
       "5           -4.986956           -9.716744           -5.630361   \n",
       "6           -5.357176           -9.875131           -5.712885   \n",
       "7           -4.722161           -9.649546           -5.570879   \n",
       "8           -6.867500          -13.046250           -8.230000   \n",
       "9           -5.465542          -10.148432           -5.836459   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0           -6.386198         -7.201027         1.785536  \n",
       "1           -6.850799         -8.017114         2.023268  \n",
       "2           -6.482076         -7.385141         1.933128  \n",
       "3           -6.477463         -7.202254         1.745740  \n",
       "4           -6.454190         -6.980825         1.842085  \n",
       "5           -6.349219         -7.038950         1.789381  \n",
       "6           -6.518956         -7.245953         1.770213  \n",
       "7           -6.457735         -6.949525         1.808180  \n",
       "8           -6.297578         -9.355641         2.804212  \n",
       "9           -6.683170         -7.429798         1.836276  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=cv_res.loc[:,['params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['RMSE']=np.sqrt(np.abs(res['mean_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'n_estimators': 173}</td>\n",
       "      <td>-36.608611</td>\n",
       "      <td>6.050505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'n_estimators': 48}</td>\n",
       "      <td>-36.218882</td>\n",
       "      <td>6.018212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'n_estimators': 118}</td>\n",
       "      <td>-36.318208</td>\n",
       "      <td>6.026459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'n_estimators': 193}</td>\n",
       "      <td>-36.319328</td>\n",
       "      <td>6.026552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'n_estimators': 324}</td>\n",
       "      <td>-36.480204</td>\n",
       "      <td>6.039884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'n_estimators': 252}</td>\n",
       "      <td>-36.848177</td>\n",
       "      <td>6.070270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'n_estimators': 196}</td>\n",
       "      <td>-36.104335</td>\n",
       "      <td>6.008688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'n_estimators': 360}</td>\n",
       "      <td>-36.665389</td>\n",
       "      <td>6.055195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>-39.166281</td>\n",
       "      <td>6.258297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'n_estimators': 212}</td>\n",
       "      <td>-35.890311</td>\n",
       "      <td>5.990852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  params  mean_test_score      RMSE\n",
       "0  {'n_estimators': 173}       -36.608611  6.050505\n",
       "1   {'n_estimators': 48}       -36.218882  6.018212\n",
       "2  {'n_estimators': 118}       -36.318208  6.026459\n",
       "3  {'n_estimators': 193}       -36.319328  6.026552\n",
       "4  {'n_estimators': 324}       -36.480204  6.039884\n",
       "5  {'n_estimators': 252}       -36.848177  6.070270\n",
       "6  {'n_estimators': 196}       -36.104335  6.008688\n",
       "7  {'n_estimators': 360}       -36.665389  6.055195\n",
       "8   {'n_estimators': 10}       -39.166281  6.258297\n",
       "9  {'n_estimators': 212}       -35.890311  5.990852"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we are getting lesser RMSE if n_estimators(no. of decision trees) is high(212). After that \n",
    "again RMSE increases.\n",
    "Lets manually take set of hyperparameters('n_estimators') close to 212 so as to get optimized results in\n",
    "GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=0),\n",
       "             param_grid={'n_estimators': [200, 201, 202, 203, 204, 205, 206,\n",
       "                                          207, 208, 209, 210, 211, 212, 213,\n",
       "                                          214, 215, 216, 217, 218, 219, 220]},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid={'n_estimators':list(range(200,221))}\n",
    "grid_scv=GridSearchCV(rf_reg,param_grid,scoring='neg_mean_squared_error',cv=5,return_train_score=True)\n",
    "grid_scv.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res1=pd.DataFrame(grid_scv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1=cv_res1.loc[:,['params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1['RMSE']=np.sqrt(np.abs(res1['mean_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'n_estimators': 200}</td>\n",
       "      <td>-36.107569</td>\n",
       "      <td>6.008957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'n_estimators': 201}</td>\n",
       "      <td>-36.162353</td>\n",
       "      <td>6.013514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'n_estimators': 202}</td>\n",
       "      <td>-36.026974</td>\n",
       "      <td>6.002247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'n_estimators': 203}</td>\n",
       "      <td>-36.090795</td>\n",
       "      <td>6.007561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'n_estimators': 204}</td>\n",
       "      <td>-36.110608</td>\n",
       "      <td>6.009210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'n_estimators': 205}</td>\n",
       "      <td>-36.130148</td>\n",
       "      <td>6.010836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'n_estimators': 206}</td>\n",
       "      <td>-36.115650</td>\n",
       "      <td>6.009630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'n_estimators': 207}</td>\n",
       "      <td>-36.159873</td>\n",
       "      <td>6.013308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'n_estimators': 208}</td>\n",
       "      <td>-36.012420</td>\n",
       "      <td>6.001035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'n_estimators': 209}</td>\n",
       "      <td>-35.975103</td>\n",
       "      <td>5.997925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'n_estimators': 210}</td>\n",
       "      <td>-35.850879</td>\n",
       "      <td>5.987560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'n_estimators': 211}</td>\n",
       "      <td>-35.790336</td>\n",
       "      <td>5.982502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'n_estimators': 212}</td>\n",
       "      <td>-35.890311</td>\n",
       "      <td>5.990852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'n_estimators': 213}</td>\n",
       "      <td>-35.928269</td>\n",
       "      <td>5.994019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'n_estimators': 214}</td>\n",
       "      <td>-35.943702</td>\n",
       "      <td>5.995307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'n_estimators': 215}</td>\n",
       "      <td>-35.799935</td>\n",
       "      <td>5.983305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'n_estimators': 216}</td>\n",
       "      <td>-35.837477</td>\n",
       "      <td>5.986441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'n_estimators': 217}</td>\n",
       "      <td>-35.838809</td>\n",
       "      <td>5.986552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'n_estimators': 218}</td>\n",
       "      <td>-35.900726</td>\n",
       "      <td>5.991721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'n_estimators': 219}</td>\n",
       "      <td>-36.035898</td>\n",
       "      <td>6.002991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'n_estimators': 220}</td>\n",
       "      <td>-36.122450</td>\n",
       "      <td>6.010196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   params  mean_test_score      RMSE\n",
       "0   {'n_estimators': 200}       -36.107569  6.008957\n",
       "1   {'n_estimators': 201}       -36.162353  6.013514\n",
       "2   {'n_estimators': 202}       -36.026974  6.002247\n",
       "3   {'n_estimators': 203}       -36.090795  6.007561\n",
       "4   {'n_estimators': 204}       -36.110608  6.009210\n",
       "5   {'n_estimators': 205}       -36.130148  6.010836\n",
       "6   {'n_estimators': 206}       -36.115650  6.009630\n",
       "7   {'n_estimators': 207}       -36.159873  6.013308\n",
       "8   {'n_estimators': 208}       -36.012420  6.001035\n",
       "9   {'n_estimators': 209}       -35.975103  5.997925\n",
       "10  {'n_estimators': 210}       -35.850879  5.987560\n",
       "11  {'n_estimators': 211}       -35.790336  5.982502\n",
       "12  {'n_estimators': 212}       -35.890311  5.990852\n",
       "13  {'n_estimators': 213}       -35.928269  5.994019\n",
       "14  {'n_estimators': 214}       -35.943702  5.995307\n",
       "15  {'n_estimators': 215}       -35.799935  5.983305\n",
       "16  {'n_estimators': 216}       -35.837477  5.986441\n",
       "17  {'n_estimators': 217}       -35.838809  5.986552\n",
       "18  {'n_estimators': 218}       -35.900726  5.991721\n",
       "19  {'n_estimators': 219}       -36.035898  6.002991\n",
       "20  {'n_estimators': 220}       -36.122450  6.010196"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=211, random_state=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_scv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look this is importance of GridSearchCV. If I had stopped at RandomizedSearchCV I would have gotten RMSE=5.99 corresponding\n",
    "to 'n_estimators=212' \n",
    "After applying GridSearchCV, I got RMSE=5.982 corresponding to 'n_estimators=211'. GREAT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=grid_scv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL STEP:TESTING OUR FINE TUNED BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test=test_set[['Hours']],test_set[['Scores']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions=final_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\t:7.069194312796209\n",
      "RMSE:\t 8.942552472642223\n"
     ]
    }
   ],
   "source": [
    "print('''MAE:\\t:{}\\nRMSE:\\t {}'''.format(mean_absolute_error(y_test,final_predictions),np.sqrt(mean_squared_error(y_test,final_predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([88.99052133])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.predict([[9.25]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, according to the data provided, if a student studies for 9.25hrs/day, he should be getting 89 marks to be exact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS PREDICTION BY LINEAR REGRESSION MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\t:4.18385989900298\n",
      "RMSE:\t 4.64744761210037\n"
     ]
    }
   ],
   "source": [
    "y_pred=lin_reg.predict(X_test_scaled)\n",
    "print('''MAE:\\t:{}\\nRMSE:\\t {}'''.format(mean_absolute_error(y_test,y_pred),np.sqrt(mean_squared_error(y_test,y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[93.69173249]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.predict(scaler.transform([[9.25]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
